{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bring mnist 784 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier with 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50, ), max_iter=10, alpha=1e-4,\n",
    "                   solver='sgd', verbose=10, random_state=1,\n",
    "                   learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32009978\n",
      "Iteration 2, loss = 0.15347534\n",
      "Iteration 3, loss = 0.11544755\n",
      "Iteration 4, loss = 0.09279764\n",
      "Iteration 5, loss = 0.07889367\n",
      "Iteration 6, loss = 0.07170497\n",
      "Iteration 7, loss = 0.06282111\n",
      "Iteration 8, loss = 0.05530788\n",
      "Iteration 9, loss = 0.04960484\n",
      "Iteration 10, loss = 0.04645355\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                            module=\"sklearn\")\n",
    "    mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier with 'adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_adam = MLPClassifier(hidden_layer_sizes=(50, ), max_iter=10, alpha=1e-4,\n",
    "                   solver='adam', verbose=10, random_state=1,\n",
    "                   learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60642772\n",
      "Iteration 2, loss = 0.41250209\n",
      "Iteration 3, loss = 0.41018109\n",
      "Iteration 4, loss = 0.43526364\n",
      "Iteration 5, loss = 0.44345262\n",
      "Iteration 6, loss = 0.45637747\n",
      "Iteration 7, loss = 0.43507076\n",
      "Iteration 8, loss = 0.40767598\n",
      "Iteration 9, loss = 0.42664405\n",
      "Iteration 10, loss = 0.46174098\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                            module=\"sklearn\")\n",
    "    mlp_adam.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output with 10 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.986800\n",
      "Test set score: 0.970000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" %mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.874800\n",
      "Test set score: 0.867000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp_adam.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" %mlp_adam.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sgd_1000 = MLPClassifier(hidden_layer_sizes=(50, ), max_iter=1000, alpha=1e-4,\n",
    "                   solver='sgd', verbose=10, random_state=1,\n",
    "                   learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_adam_1000 = MLPClassifier(hidden_layer_sizes=(50, ), max_iter=1000, alpha=1e-4,\n",
    "                   solver='adam', verbose=10, random_state=1,\n",
    "                   learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32009978\n",
      "Iteration 2, loss = 0.15347534\n",
      "Iteration 3, loss = 0.11544755\n",
      "Iteration 4, loss = 0.09279764\n",
      "Iteration 5, loss = 0.07889367\n",
      "Iteration 6, loss = 0.07170497\n",
      "Iteration 7, loss = 0.06282111\n",
      "Iteration 8, loss = 0.05530788\n",
      "Iteration 9, loss = 0.04960484\n",
      "Iteration 10, loss = 0.04645355\n",
      "Iteration 11, loss = 0.04082169\n",
      "Iteration 12, loss = 0.03828222\n",
      "Iteration 13, loss = 0.03557957\n",
      "Iteration 14, loss = 0.03054891\n",
      "Iteration 15, loss = 0.02924761\n",
      "Iteration 16, loss = 0.02610471\n",
      "Iteration 17, loss = 0.02363894\n",
      "Iteration 18, loss = 0.02208186\n",
      "Iteration 19, loss = 0.01932900\n",
      "Iteration 20, loss = 0.01830387\n",
      "Iteration 21, loss = 0.01639227\n",
      "Iteration 22, loss = 0.01392950\n",
      "Iteration 23, loss = 0.01270193\n",
      "Iteration 24, loss = 0.01234102\n",
      "Iteration 25, loss = 0.01081313\n",
      "Iteration 26, loss = 0.01028644\n",
      "Iteration 27, loss = 0.00896707\n",
      "Iteration 28, loss = 0.00744908\n",
      "Iteration 29, loss = 0.00707946\n",
      "Iteration 30, loss = 0.00573869\n",
      "Iteration 31, loss = 0.00499554\n",
      "Iteration 32, loss = 0.00477064\n",
      "Iteration 33, loss = 0.00395458\n",
      "Iteration 34, loss = 0.00355619\n",
      "Iteration 35, loss = 0.00375497\n",
      "Iteration 36, loss = 0.00304228\n",
      "Iteration 37, loss = 0.00264245\n",
      "Iteration 38, loss = 0.00241425\n",
      "Iteration 39, loss = 0.00234957\n",
      "Iteration 40, loss = 0.00233803\n",
      "Iteration 41, loss = 0.00204653\n",
      "Iteration 42, loss = 0.00199057\n",
      "Iteration 43, loss = 0.00190567\n",
      "Iteration 44, loss = 0.00180530\n",
      "Iteration 45, loss = 0.00175054\n",
      "Iteration 46, loss = 0.00168160\n",
      "Iteration 47, loss = 0.00162517\n",
      "Iteration 48, loss = 0.00159676\n",
      "Iteration 49, loss = 0.00154993\n",
      "Iteration 50, loss = 0.00152799\n",
      "Iteration 51, loss = 0.00146697\n",
      "Iteration 52, loss = 0.00145257\n",
      "Iteration 53, loss = 0.00143422\n",
      "Iteration 54, loss = 0.00135888\n",
      "Iteration 55, loss = 0.00134281\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                            module=\"sklearn\")\n",
    "    mlp_sgd_1000.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60642772\n",
      "Iteration 2, loss = 0.41250209\n",
      "Iteration 3, loss = 0.41018109\n",
      "Iteration 4, loss = 0.43526364\n",
      "Iteration 5, loss = 0.44345262\n",
      "Iteration 6, loss = 0.45637747\n",
      "Iteration 7, loss = 0.43507076\n",
      "Iteration 8, loss = 0.40767598\n",
      "Iteration 9, loss = 0.42664405\n",
      "Iteration 10, loss = 0.46174098\n",
      "Iteration 11, loss = 0.49915406\n",
      "Iteration 12, loss = 0.52411150\n",
      "Iteration 13, loss = 0.47356631\n",
      "Iteration 14, loss = 0.48478371\n",
      "Iteration 15, loss = 0.46341648\n",
      "Iteration 16, loss = 0.47058690\n",
      "Iteration 17, loss = 0.47210828\n",
      "Iteration 18, loss = 0.52342594\n",
      "Iteration 19, loss = 0.56260587\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                            module=\"sklearn\")\n",
    "    mlp_adam_1000.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training set score: 1.000000\n",
      "SGD Test set score: 0.973100\n",
      "Adam Training set score: 0.876067\n",
      "Adam Test set score: 0.875200\n"
     ]
    }
   ],
   "source": [
    "print(\"SGD Training set score: %f\" % mlp_sgd_1000.score(X_train, y_train))\n",
    "print(\"SGD Test set score: %f\" %mlp_sgd_1000.score(X_test, y_test))\n",
    "print(\"Adam Training set score: %f\" % mlp_adam_1000.score(X_train, y_train))\n",
    "print(\"Adam Test set score: %f\" %mlp_adam_1000.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
